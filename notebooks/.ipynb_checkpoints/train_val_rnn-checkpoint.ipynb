{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is disabled, cuDNN 5005)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "No module named model_basic",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-af194910fcee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmodel_basic\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named model_basic"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "import cv2\n",
    "import random\n",
    "from model_basic import *\n",
    "from image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import SimpleRNN, LSTM, GRU\n",
    "from keras.optimizers import RMSprop, Adadelta\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.core import Dense, Activation, TimeDistributedDense, Dropout, Reshape, Flatten\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.models import model_from_json\n",
    "\n",
    "\n",
    "print 'packages loaded!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path to data\n",
    "path2set=\"../dcom/TrainingSet/\"\n",
    "path2numpy = path2set+\"numpy/\"\n",
    "path2nfolds=path2numpy+'nfolds/'\n",
    "foldnm=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "def load_data(path):\n",
    "    print ('_' *50)\n",
    "    print 'please wait to load data ...'\n",
    "    start_time=time.time()\n",
    "    tmp = np.load(path)\n",
    "    X=tmp['X']\n",
    "    Y=tmp['Y'] \n",
    "    print ('X shape: ', X.shape)\n",
    "    print ('Y shape: ',Y.shape)\n",
    "    print ('Min and Max X: ', np.min(X), np.max(X))\n",
    "    print ('Min and Max Y: ', np.min(Y), np.max(Y))\n",
    "    elapsed_time=time.time()-start_time\n",
    "    print 'Elapsed time: %d seconds' % elapsed_time\n",
    "    print ('_' *50)\n",
    "    return X,Y\n",
    "\n",
    "def grays_to_RGB(img):\n",
    "    # turn 2D grayscale image into grayscale RGB\n",
    "    return np.dstack((img, img, img))\n",
    "\n",
    "def image_with_mask(img, mask):\n",
    "    maximg=np.max(img)\n",
    "    mask=np.asarray(mask,dtype='uint8')\n",
    "    if np.max(mask)<=1:\n",
    "        mask=mask*255\n",
    "    # returns a copy of the image with edges of the mask added in red\n",
    "    img_color = grays_to_RGB(img)\n",
    "    mask_edges = cv2.Canny(mask, 100, 200) > 0\n",
    "    #print np.sum(mask_edges)\n",
    "    img_color[mask_edges, 0] = maximg  # set channel 0 to bright red, green & blue channels to 0\n",
    "    img_color[mask_edges, 1] = 0\n",
    "    img_color[mask_edges, 2] = 0\n",
    "    img_color=img_color/float(np.max(img))\n",
    "    return img_color\n",
    "\n",
    "# 5D array image display\n",
    "def disp_img_mask(img,mask=None,ind=None):\n",
    "    # img and mask are 5d arrays, N*time*C*H*W\n",
    "    img=np.squeeze(img)\n",
    "    \n",
    "    # check for random dispaly or based on input\n",
    "    if ind is None:\n",
    "        n1=np.random.randint(img.shape[0])\n",
    "    else:\n",
    "        n1=ind\n",
    "        \n",
    "    I1=img[n1,:]\n",
    "    print I1.shape\n",
    "    \n",
    "    if mask is None:\n",
    "        M1=np.zeros(I1.shape,dtype='uint8')\n",
    "    else:\n",
    "        mask=np.squeeze(mask)\n",
    "        M1=mask[n1,:]\n",
    "    print M1.shape\n",
    "    \n",
    "    r,c=2,5\n",
    "    for k in range(r*c):\n",
    "        plt.subplot(r,c,k+1)\n",
    "        imgmask=image_with_mask(I1[k,:],M1[k,:])\n",
    "        plt.imshow(imgmask)\n",
    "        plt.title('s: %s, maxI: %s' %(n1,np.max(I1[k,:])))\n",
    "    plt.show()\n",
    "        \n",
    "# preprocess\n",
    "def preprocess(X,Y,param_prep):\n",
    "    \n",
    "    # get params\n",
    "    h=param_prep['img_rows']\n",
    "    w=param_prep['img_cols']    \n",
    "    crop=param_prep['crop']\n",
    "    imr=param_prep['resize_factor'] # image resize\n",
    "    norm_ena=param_prep['norm_ena'] # normalization \n",
    "    \n",
    "    print ('_' *50)\n",
    "    start_time=time.time()\n",
    "    Y=np.asarray(Y,dtype='uint8')\n",
    "    # center crop h*w\n",
    "    if crop is 'center':\n",
    "        H,W=X.shape[2:]\n",
    "        hc=(H-h)/2\n",
    "        wc=(W-w)/2\n",
    "        X=X[:,:,hc:H-hc,wc:W-wc]\n",
    "        Y = Y[:,:,hc:H-hc,wc:W-wc]\n",
    "    elif crop is 'random':\n",
    "        H,W=X.shape[2:]\n",
    "        hc=(H-h)/2\n",
    "        wc=(W-w)/2\n",
    "        hcr=np.random.randint(hc)\n",
    "        wcr=np.random.randint(wc)\n",
    "        X=X[:,:,hc:H-hc,wc:W-wc]\n",
    "        Y = Y[:,:,hc:H-hc,wc:W-wc]\n",
    "        \n",
    "    print ('X shape: ', X.shape)\n",
    "    print ('Y shape: ',Y.shape)\n",
    "\n",
    "    print 'please wait to resize images ...'\n",
    "    if imr<1:\n",
    "        img_h=int(X.shape[2]*imr) # rows\n",
    "        img_w=int(X.shape[3]*imr) # columns\n",
    "        X_r=np.zeros([X.shape[0],1,img_h,img_w],dtype=X.dtype)\n",
    "        Y_r=np.zeros([Y.shape[0],1,img_h,img_w],dtype=Y.dtype)\n",
    "        for k1 in range(len(X)):\n",
    "            X_r[k1, 0] = cv2.resize(X[k1, 0], (img_w, img_h), interpolation=cv2.INTER_CUBIC)\n",
    "            Y_r[k1, 0] = cv2.resize(Y[k1, 0], (img_w, img_h), interpolation=cv2.INTER_CUBIC)\n",
    "    else:\n",
    "        X_r=X\n",
    "        Y_r=Y\n",
    "    \n",
    "    # normalization\n",
    "    if norm_ena is True:\n",
    "        X_r=np.array(X_r,dtype='float32')\n",
    "        for k in range(X_r.shape[0]):\n",
    "            for m in range(X_r.shape[1]):\n",
    "                mean = np.mean(X_r[k,m,0])  # mean       \n",
    "                sigma = np.std(X_r[k,m,0])  # std\n",
    "                if sigma<1e-5:\n",
    "                    sigma=1\n",
    "                X_r[k,m,:,:] = X_r[k,m,:,:]-mean\n",
    "                X_r[k,m,:,:] = X_r[k,m,:,:]/ sigma\n",
    "\n",
    "    print ('X_r size: ', X_r.shape)\n",
    "    print ('Y_r size: ',Y_r.shape)\n",
    "    print ('Min and Max  X_r: ', np.min(X_r), np.max(X_r))\n",
    "    print ('Min and Max  Y_r: ',  np.min(Y_r),  np.max(Y_r))        \n",
    "        \n",
    "    # add time dimension\n",
    "    X_r=np.expand_dims(X_r,axis=2)\n",
    "    Y_r=np.expand_dims(Y_r,axis=2)\n",
    "    \n",
    "    print ('X_r size: ', X_r.shape)\n",
    "    print ('Y_r size: ',Y_r.shape)\n",
    "    print ('Min and Max  X_r: ', np.min(X_r), np.max(X_r))\n",
    "    print ('Min and Max  Y_r: ',  np.min(Y_r),  np.max(Y_r))\n",
    "\n",
    "    elapsed_time=time.time()-start_time\n",
    "    print 'Elapsed time: %d seconds' % elapsed_time\n",
    "    print ('_' *50)\n",
    "    return X_r,Y_r\n",
    "\n",
    "# convert mask to volumes\n",
    "def mask2volume(Y,h=1):\n",
    "    \n",
    "    # number of dataset\n",
    "    N1=Y.shape[0]\n",
    "    \n",
    "    # number of slices\n",
    "    N2=Y.shape[1]\n",
    "    \n",
    "    V=np.zeros(N1)\n",
    "    for k in range(N1):\n",
    "        Vz=0\n",
    "        for z in range(N2-1):\n",
    "            Yz=Y[k,z,:]\n",
    "            Yzp1=Y[k,z+1,:]\n",
    "            Az=np.sum(Yz)\n",
    "            Azp1=np.sum(Yzp1)\n",
    "            Vz=Vz+.5*(Az+Azp1)\n",
    "        V[k]=Vz*h            \n",
    "    \n",
    "    Vn=V/np.max(V)\n",
    "    return V,Vn\n",
    "\n",
    "# random data generator\n",
    "datagen = ImageDataGenerator(featurewise_center=False,\n",
    "        samplewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False,\n",
    "        rotation_range=75,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.0,\n",
    "        zoom_range=0,\n",
    "        channel_shift_range=0.0,\n",
    "        fill_mode='nearest',\n",
    "        cval=0.0,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        dim_ordering='th')\n",
    "        \n",
    "def iterate_minibatches(inputs1 , targets,  batchsize, shuffle=False, augment=True):\n",
    "    assert len(inputs1) == len(targets)\n",
    " \n",
    "    if shuffle is True:\n",
    "        indices = np.arange(len(inputs1))\n",
    "        np.random.shuffle(indices)\n",
    "        print 'shuffled!'\n",
    "    for start_idx in range(0, len(inputs1) - batchsize + 1, batchsize):\n",
    "        if shuffle is True:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "            print 'shuffled!'\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        x = inputs1[excerpt]\n",
    "        y = targets[excerpt] \n",
    "        for  xxt,yyt in datagen.flow(x, y , batch_size=x.shape[0]):\n",
    "            x = xxt.astype(np.float32) \n",
    "            y = yyt \n",
    "            break\n",
    "\n",
    "    #yield x, np.array(y, dtype=np.uint8)         \n",
    "    return x, np.array(y, dtype=np.uint8)         \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load train data\n",
    "X_train,Y_train=load_data(path2nfolds + 'trainfold'+str(foldnm)+'.npz')\n",
    "\n",
    "# load test data\n",
    "X_test,Y_test=load_data(path2nfolds + 'testfold'+str(foldnm)+'.npz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# display sample image\n",
    "plt.figure(figsize=(20,10)) \n",
    "disp_img_mask(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pre-processing \n",
    "\n",
    "param_prep={\n",
    "    'img_rows': 192,\n",
    "    'img_cols': 192,\n",
    "    'crop'    : 'center',\n",
    "    'resize_factor': 1,\n",
    "    'norm_ena' : True,\n",
    "}\n",
    "\n",
    "# preprocess train data\n",
    "X_train_r,Y_train_r=preprocess(X_train,Y_train,param_prep)\n",
    "\n",
    "# preprocess test data\n",
    "X_test_r,Y_test_r=preprocess(X_test,Y_test,param_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# display sample image\n",
    "plt.figure(figsize=(20,10)) \n",
    "disp_img_mask(X_train_r,Y_train_r)\n",
    "\n",
    "plt.figure(figsize=(20,10)) \n",
    "disp_img_mask(X_test_r,Y_test_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# labels to volumes\n",
    "v_train,y_train=mask2volume(Y_train)\n",
    "v_test,y_test=mask2volume(Y_test)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(v_train,30)\n",
    "plt.hist(v_test,10)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(y_train,30)\n",
    "plt.hist(y_test,10)\n",
    "plt.title('normalized')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# define some run parameters\n",
    "batch_size      = 1\n",
    "nb_epochs       = 20\n",
    "examplesPer     = X_train_r.shape[0]\n",
    "timestep        = X_train_r.shape[1]\n",
    "hidden_units    = 200\n",
    "h,w= X_train_r.shape[3:5]\n",
    "\n",
    "#define our time-distributed setup\n",
    "model = Sequential()\n",
    "\n",
    "model.add(TimeDistributed(Convolution2D(16, 3, 3, border_mode='valid',activation='relu'), input_shape=(timestep,1,h,w)))\n",
    "model.add(TimeDistributed(Convolution2D(16, 3, 3, border_mode='valid',activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2),border_mode='valid')))\n",
    "\n",
    "model.add(TimeDistributed(Convolution2D(32, 3, 3, border_mode='valid',activation='relu')))\n",
    "model.add(TimeDistributed(Convolution2D(32, 3, 3, border_mode='valid',activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2),border_mode='valid')))\n",
    "\n",
    "model.add(TimeDistributed(Convolution2D(64, 3, 3, border_mode='valid',activation='relu')))\n",
    "model.add(TimeDistributed(Convolution2D(64, 3, 3, border_mode='valid',activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2),border_mode='valid')))\n",
    "\n",
    "model.add(TimeDistributed(Convolution2D(128, 3, 3, border_mode='valid',activation='relu')))\n",
    "model.add(TimeDistributed(Convolution2D(128, 3, 3, border_mode='valid',activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2),border_mode='valid')))\n",
    "\n",
    "model.add(TimeDistributed(Convolution2D(256, 3, 3, border_mode='valid',activation='relu')))\n",
    "model.add(TimeDistributed(Convolution2D(256, 3, 3, border_mode='valid',activation='relu')))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(Activation('relu'))\n",
    "model.add(GRU(output_dim=100,return_sequences=False))\n",
    "#model.add(GRU(output_dim=50,return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "\n",
    "rmsprop = RMSprop()\n",
    "model.compile(loss='mean_squared_error', optimizer=rmsprop)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'train in progress ...'\n",
    "\n",
    "if  not os.path.exists('./output/weights'):\n",
    "    os.makedirs('./output/weights')\n",
    "    print 'weights folder created'\n",
    "filepath=\"./output/weights/fold\"+str(foldnm)+\"-volume_weights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only='True',mode='min')\n",
    "\n",
    "\n",
    "param_prep={\n",
    "    'img_rows': 192,\n",
    "    'img_cols': 192,\n",
    "    'crop'    : 'center',\n",
    "    'resize_factor': 1,\n",
    "    'norm_ena' : True,\n",
    "}\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "# number of epochs\n",
    "nb_epoch=500\n",
    "start_time=time.time()\n",
    "score_train=[]\n",
    "score_test=[]\n",
    "\n",
    "for epoch in range(nb_epoch):\n",
    "    print '-'*50\n",
    "    print 'epoch: %s' %epoch\n",
    "    seed = np.random.randint(0, 999999)\n",
    "\n",
    "    # augment training\n",
    "    Xaug,Yaug=iterate_minibatches( X_train, Y_train , X_train.shape[0], shuffle=False)\n",
    "    X_train_aug,Y_train_aug=preprocess(Xaug,Yaug,param_prep)\n",
    "    _,y_train_aug=mask2volume(Y_train_aug)\n",
    "    #X_train_aug=X_train_r\n",
    "    #disp_img_mask(X_train_aug,Y_train_aug)\n",
    "    \n",
    "    model.fit(X_train_aug, y_train_aug, validation_data=(X_test_r, y_test),nb_epoch=1, batch_size=1,verbose=0,shuffle=True,callbacks=[checkpoint])\n",
    "    \n",
    "    s_train=model.evaluate(X_train_aug, y_train,verbose=0)\n",
    "    s_test=model.evaluate(X_test_r, y_test,verbose=0)\n",
    "    print 'train: %.5f' %s_train    \n",
    "    print 'test: %.5f' %s_test\n",
    "\n",
    "    score_train=np.append(score_train,s_train)\n",
    "    score_test=np.append(score_test,s_test)    \n",
    "\n",
    "plt.plot(score_train)\n",
    "plt.plot(score_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights_path=\"./output/weights/fold\"+str(foldnm)+\"-volume_weights.hdf5\"\n",
    "print weights_path\n",
    "model.load_weights(weights_path)\n",
    "\n",
    "s_train=model.evaluate(X_train_aug, y_train_aug,verbose=0)\n",
    "s_test=model.evaluate(X_test_r, y_test,verbose=0)\n",
    "print 'train: %.5f' %s_train    \n",
    "print 'test: %.5f' %s_test\n",
    "\n",
    "y_pred1=model.predict(X_train_aug)\n",
    "#y_pred1=np.reshape(y_pred1,(1,y_pred1.shape[0]))\n",
    "y_pred2=model.predict(X_test_r)\n",
    "v_train,_=mask2volume(Y_train_aug)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(v_train)\n",
    "y_pred1=np.max(v_train)*y_pred1\n",
    "plt.plot(y_pred1)\n",
    "plt.title('train')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "v_test,_=mask2volume(Y_test)\n",
    "y_pred2=np.max(v_test)*y_pred2\n",
    "plt.plot(v_test)\n",
    "plt.plot(y_pred2)\n",
    "plt.title('test')\n",
    "plt.legend('ground truth','automatic',loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xaug,yaug=iterate_minibatches( X_train, Y_train , X_train.shape[0], shuffle=False)\n",
    "Xaug,Yaug=preprocess(xaug,yaug,param_prep)\n",
    "print np.max(xaug)\n",
    "# display sample image\n",
    "plt.figure(figsize=(20,10)) \n",
    "disp_img_mask(Xaug,Yaug)\n",
    "\n",
    "vaug,vaugn=mask2volume(Yaug)\n",
    "print vaug,vaugn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
